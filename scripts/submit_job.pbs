#!/bin/bash
#PBS -N neural_operator_3d
#PBS -l select=2:ncpus=8:ngpus=1:mem=32gb
#PBS -l walltime=24:00:00
#PBS -q gpu
#PBS -j oe
#PBS -o logs/pbs_output.log

# Set up environment
module load python/3.9
module load cuda/11.8

# Activate virtual environment (adjust path as needed)
source /path/to/venv/bin/activate

# Set working directory
cd $PBS_O_WORKDIR

# Create logs directory
mkdir -p logs

# Parse PBS nodefile to get master address
NODEFILE=$PBS_NODEFILE
if [ -f "$NODEFILE" ]; then
    MASTER_NODE=$(head -n 1 $NODEFILE | cut -d'.' -f1)
    NUM_NODES=$(cat $NODEFILE | wc -l)
    NUM_GPUS=$NUM_NODES  # Assuming 1 GPU per node
    
    echo "Master node: $MASTER_NODE"
    echo "Number of nodes: $NUM_NODES"
    echo "Number of GPUs: $NUM_GPUS"
else
    echo "Warning: PBS_NODEFILE not found, running in single-node mode"
    MASTER_NODE=$(hostname | cut -d'.' -f1)
    NUM_NODES=1
    NUM_GPUS=1
fi

# Set environment variables for distributed training
export MASTER_ADDR=$MASTER_NODE
export MASTER_PORT=29500

# Launch distributed training using torchrun
# Note: For PBS, we use srun or mpirun, but torchrun is simpler
# If PBS_ARRAY_INDEX is not set, assume single job (not array)
if [ -z "$PBS_ARRAY_INDEX" ]; then
    NODE_RANK=0
else
    NODE_RANK=$PBS_ARRAY_INDEX
fi

torchrun \
    --nnodes=$NUM_NODES \
    --nproc_per_node=1 \
    --node_rank=$NODE_RANK \
    --master_addr=$MASTER_ADDR \
    --master_port=$MASTER_PORT \
    main.py \
    --config config.yaml \
    --mode train

echo "Job completed at $(date)"
